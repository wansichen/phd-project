{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a356ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "input_size=784\n",
    "output_size=784\n",
    "font = {'size'   : 20}\n",
    "plt.rc('font', **font)\n",
    "torch.set_default_dtype(torch.float64)\n",
    "class Feedforward(torch.nn.Module):\n",
    "        def __init__(self, input_size, hidden_size,h_size,xinit=[],xfinal=[]):\n",
    "            \n",
    "            super(Feedforward, self).__init__()\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size  = hidden_size\n",
    "            self.h_size=h_size\n",
    "            self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "            self.fc2=torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
    "            self.relu = torch.nn.ReLU()\n",
    "            self.fc3 = torch.nn.Linear(self.hidden_size, 10)\n",
    "            self.sigmoid = torch.nn.Sigmoid()\n",
    "            self.xinit=xinit\n",
    "            self.xfinal=xfinal\n",
    "        def forward(self, x):\n",
    "            \n",
    "            fc1 = self.fc1(x)\n",
    "    \n",
    "            x = self.relu(fc1)\n",
    "            self.xinit=x\n",
    "            #for layer in range(self.h_size):\n",
    "             #   x = F.relu(self.fc2(x))\n",
    "            x=Feedforward.internals(self,x)\n",
    "            self.xfinal=x\n",
    "            output = self.fc3(x)\n",
    "            output = F.log_softmax(output,dim=1)\n",
    "            return output\n",
    "        def internals(self,x):\n",
    "            for layer in range(self.h_size):\n",
    "                x = F.relu(self.fc2(x))\n",
    "            return x\n",
    "        #def encoder(self,x):\n",
    "            #return\n",
    "        #def decoder(self,x):\n",
    "        #    return\n",
    "        \n",
    "        def init(self):\n",
    "            return self.xinit\n",
    "        def final(self):\n",
    "            \n",
    "            return self.xfinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd6fe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\"./data\", download=True, transform=\n",
    "                                                transforms.Compose([transforms.ToTensor()]))\n",
    "test_set = torchvision.datasets.FashionMNIST(\"./data\", download=True, train=False, transform=\n",
    "                                               transforms.Compose([transforms.ToTensor()]))  \n",
    "train_loader = torch.utils.data.DataLoader(train_set, \n",
    "                                           batch_size=100,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set,\n",
    "                                          batch_size=100,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b8a9955",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m i\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b,(x_train,y_train) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtrain_loader\u001b[49m):\n\u001b[1;32m      4\u001b[0m      visualisation(x_train[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample image \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "def add_noise(inputs,strength):\n",
    "    \n",
    "    noise = torch.randn_like(inputs)*strength\n",
    "    return inputs + noise\n",
    "def validation(test_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "     #valid_loss = criterion(outputs, batch_features.view(batch_size,-1))\n",
    "        loss=0\n",
    "        for batch_features, _ in test_loader:\n",
    "            #input=add_noise(batch_features,).view(100, -1)\n",
    "            input_image=add_noise(batch_features,noise_strength).view(batch_size, -1)\n",
    "            batch_feature = batch_features.view(batch_size, -1)\n",
    "            outputs = model(input_image)\n",
    "            valid_loss = criterion(outputs, input_image) \n",
    "            #accuracy+=kl_div(outputs,batch_features)/batch_size\n",
    "            loss += valid_loss.item()\n",
    "    return loss/len(test_loader)\n",
    "            \n",
    "def kl_div(output_image,input_image):\n",
    "    accuracy=0\n",
    "    kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "    for i in range(len(input_image)):\n",
    "        input_spectrum=torch.histogram(input_image[i].cpu(), bins=256, density=True)\n",
    "        output_spectrum=torch.histogram(output_image[i].cpu(), bins=256, density=True)\n",
    "        accuracy+=kl_loss(input_spectrum[i],output_spectrum[i])\n",
    "    return accuracy/len(input_image)/256\n",
    "\n",
    "def iteration(model,initial_inputs,no_of_repetition,epoch):\n",
    "    y_pred=initial_inputs\n",
    "    for i in range(no_of_repetition):\n",
    "        x_train=y_pred\n",
    "        y_pred=model.internals(x_train)\n",
    "    return x_train,y_pred,model \n",
    "\n",
    "def asymptotic_jacobian(model,initial_input,no_of_images,no_of_repetition):\n",
    "    ave_jac=0\n",
    "    for j in range(no_of_repetition):\n",
    "\n",
    "        x_train=initial_input\n",
    "        y_pred=x_train\n",
    "        mean_jacobian=0\n",
    "        for i in range(no_of_images):\n",
    "            x=x_train[i]\n",
    "            res=torch.autograd.functional.jacobian(model.internals,x)\n",
    "            norm=torch.norm(res).cpu()\n",
    "            mean_jacobian+=1/np.sqrt(output_size)*norm\n",
    "        mean_jacobian=mean_jacobian/no_of_images\n",
    "        ave_jac+=mean_jacobian\n",
    "    average_jacobian=ave_jac/no_of_repetition\n",
    "    return average_jacobian\n",
    "\n",
    "def spectral_radius(model,initial_input,no_of_repetition,no_of_images):\n",
    "    result=[]\n",
    "   \n",
    "    output=initial_input\n",
    "    product=torch.eye(n=input_size,m=output_size)\n",
    "    \n",
    "    spectral=0\n",
    "\n",
    "    for i in range(no_of_repetition):\n",
    "        \n",
    "        res=torch.autograd.functional.jacobian(model.internals,initial_input)\n",
    "        product=torch.matmul(product,res)\n",
    "        output=model(initial_input)\n",
    "        initial_input=output\n",
    "    \n",
    "    s,v=torch.linalg.eig(product)\n",
    "    #print(s)\n",
    "    abs=torch.abs(s)\n",
    "    spectral=torch.max(abs).item()\n",
    "    return spectral\n",
    "\n",
    "def poincare_plot(model,initial_input,dimension_vector,no_of_repetition,colour,epoch):\n",
    "    xt=[]\n",
    "    xtminus=[]\n",
    "    \n",
    "    output=initial_input\n",
    "    \n",
    "    for i in range(no_of_repetition):\n",
    "        \n",
    "        initial_input=output\n",
    "        output=model.internals(initial_input)\n",
    "        \n",
    "        xt.append(1/output_size*torch.dot(output,dimension_vector).item())\n",
    "        xtminus.append(1/output_size*torch.dot(initial_input,dimension_vector).item())\n",
    "    \n",
    "    return xt,xtminus\n",
    "  \n",
    "    \n",
    "\n",
    "\n",
    "def asymptotic_distance(xinfinity_unperturbed,xinfinity_perturbed,perturbation):\n",
    "    result=[]\n",
    "    for i in range(len(xinfinity_unperturbed)):\n",
    "    \n",
    "        sum=0\n",
    "        \n",
    "        for j in range(len(xinfinity_unperturbed[i])):\n",
    "            \n",
    "            temp=np.linalg.norm(xinfinity_unperturbed[i][j]-xinfinity_perturbed[i][j])\n",
    "            sum+=temp\n",
    "        \n",
    "        result.append(1/output_size*1/len(xinfinity_unperturbed[i])*sum) \n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def calculation(model,no_of_images,no_of_repetition,ave_jacobian,spectral_radiuses,image,epoch):\n",
    "    spectral=0\n",
    "    \n",
    "    model_clone=Feedforward(784,784,2)\n",
    "    model_clone.load_state_dict(copy.deepcopy(model.state_dict()))\n",
    "\n",
    "    x_train,y_pred,model_clone=iteration(model_clone,image,asymptotic_repetition,epoch)   \n",
    "    ave_jac = asymptotic_jacobian(model_clone,x_train,no_of_images,no_of_repetition)\n",
    "   \n",
    "    average_jacobian.append(ave_jac)\n",
    "    \n",
    "    #for i in range(no_of_images):\n",
    "    \n",
    "        #spectral+=spectral_radius(model_clone,x_train[i],no_of_repetition,no_of_images)\n",
    "    \n",
    "   # spectral_radiuses.append(spectral/no_of_images)\n",
    "    return x_train,y_pred,average_jacobian,spectral_radiuses,model_clone\n",
    "\n",
    "\n",
    "def asymptotic_iteration(model,initial_inputs,perturbed_inputs,no_of_repetition,no_of_image,cutoff):\n",
    "    \n",
    "    y_pred_unperturbed=initial_inputs\n",
    "    y_pred_perturbed=perturbed_inputs\n",
    "    \n",
    "    distance=[]\n",
    "    hidden_layer=[]\n",
    "    hiddens=[]\n",
    "    chaos=0\n",
    "    divergent=0\n",
    "\n",
    "    for i in range(no_of_repetition):\n",
    "        x_train_unperturbed=y_pred_unperturbed\n",
    "        y_pred_unperturbed=model.internals(x_train_unperturbed)\n",
    "        \n",
    "       \n",
    "        x_train_perturbed=y_pred_perturbed\n",
    "        y_pred_perturbed=model.internals(x_train_perturbed)\n",
    "        \n",
    "        diff=0        \n",
    "        for j in range(no_of_image):\n",
    "            result=torch.norm(y_pred_unperturbed[j]-y_pred_perturbed[j])\n",
    "  \n",
    "            diff+=result\n",
    "            if result>cutoff and i==no_of_repetition-1:\n",
    "                chaos+=1\n",
    "            \n",
    "        distance.append(diff.detach().numpy()/no_of_image)\n",
    "        #print(diff.detach().numpy())\n",
    "    return distance,hidden_layer,chaos/no_of_image,divergent\n",
    "\n",
    "def visualisation(xfinals,epoch,name,bool):\n",
    "    plt.imshow(xfinals.reshape(28,28), cmap=\"gray\")\n",
    "    if bool:\n",
    "        plt.savefig(str(name)+\" image:\"+str(epoch+1)+\".jpg\")\n",
    "    plt.show()\n",
    "    print(str(name)+\" epoch:\"+str(epoch+1)+\".jpg\")\n",
    "def divergence(values):\n",
    "    result=np.abs(values[-1]-values[-2])\n",
    "    if result>np.abs(values[2]-values[1]):\n",
    "        return 1\n",
    "    return 0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85295a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "epochs=100\n",
    "asymptotic_repetition=200\n",
    "\n",
    "\n",
    "#projected_jacobian=[]\n",
    "ave_len=5\n",
    "\n",
    "\n",
    "no_of_images,no_of_repetition=20,100\n",
    "colour=np.arange(1,no_of_repetition+1)\n",
    "perturbation_strength=10**(-10)\n",
    "noise_strength=10**(-3)\n",
    "interval=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ef8938",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_loader)):\n",
    "    visualisation(train_loader[i][0],i,True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
