{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11b20589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1106"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "from typing import Any\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn.parameter import Parameter, UninitializedParameter\n",
    "from torch import functional as F\n",
    "\n",
    "from torch.nn import Module\n",
    "from scipy.stats import levy_stable\n",
    "from torch.distributions.pareto import Pareto\n",
    "from torch.nn import init\n",
    "from torch.distributions.cauchy import Cauchy\n",
    "from torch.distributions.laplace import Laplace\n",
    "from numpy.random import standard_t\n",
    "seed=0\n",
    "#torch.cuda.manual_seed_all(seed)\n",
    "with torch.cuda.device('cuda:0'):\n",
    "    torch.cuda.empty_cache()\n",
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbd7b319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.62325557e-01 2.55046807e+00 3.08194262e+00 ... 2.76844003e+01\n",
      " 7.99028326e+04 2.84999956e+01]\n",
      "[2.81162779e-01 1.27523403e+00 1.54097131e+00 ... 1.38422001e+01\n",
      " 3.99514163e+04 1.42499978e+01]\n",
      "2000\n",
      "-123970.09870460334\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "a=0.5\n",
    "T=1\n",
    "epsilon=1\n",
    "m=T*epsilon\n",
    "s=(np.random.pareto(a, 2000)/2)\n",
    "print(s)\n",
    "print(s/2)\n",
    "#np.append()\n",
    "s=np.append(np.random.pareto(a, 2000)[:1000],(-1*np.random.pareto(a,2000)[:1000]))\n",
    "print(s.size)\n",
    "print(s.min())\n",
    "# shape and mode\n",
    "#s = (np.random.pareto(a, 1000) + 1) * m\n",
    "plt.hist(s,bins=1000,density=True)\n",
    "#plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9de32dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(tensor):\n",
    "    # Calculate the mean\n",
    "    mean = torch.mean(tensor)\n",
    "    # Calculate the variance\n",
    "    second = torch.mean(torch.pow(tensor,2))\n",
    "    third = torch.mean(torch.pow(tensor,3))\n",
    "    fourth=torch.mean(torch.pow(tensor,4))\n",
    "    # Calculate the standard deviation\n",
    "    var=torch.var(tensor)\n",
    "    std = torch.sqrt(var)\n",
    "    # Calculate the z-scores\n",
    "    zscores = (tensor - mean) / std\n",
    "    # Calculate the skewness\n",
    "    skew = torch.mean(zscores ** 3)\n",
    "    # Calculate the kurtosis\n",
    "    kurt = torch.mean(zscores ** 4) - 3\n",
    "    #print(\"fourth moment\")\n",
    "    #print(fourth)\n",
    "    #Return the results as a tuple\n",
    "    return mean, second, skew, kurt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d59c585",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_tuning=1\n",
    "J0=0\n",
    "J1=10**-3\n",
    "## initial =1\n",
    "class Linear(Module):\n",
    "    r\"\"\"Applies a linear transformation to the incoming data: :math:`y = xA^T + b`\n",
    "\n",
    "    This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
    "\n",
    "    On certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n",
    "\n",
    "    Args:\n",
    "        in_features: size of each input sample\n",
    "        out_features: size of each output sample\n",
    "        bias: If set to ``False``, the layer will not learn an additive bias.\n",
    "            Default: ``True``\n",
    "\n",
    "    Shape:\n",
    "        - Input: :math:`(*, H_{in})` where :math:`*` means any number of\n",
    "          dimensions including none and :math:`H_{in} = \\text{in\\_features}`.\n",
    "        - Output: :math:`(*, H_{out})` where all but the last dimension\n",
    "          are the same shape as the input and :math:`H_{out} = \\text{out\\_features}`.\n",
    "\n",
    "    Attributes:\n",
    "        weight: the learnable weights of the module of shape\n",
    "            :math:`(\\text{out\\_features}, \\text{in\\_features})`. The values are\n",
    "            initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`, where\n",
    "            :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
    "        bias:   the learnable bias of the module of shape :math:`(\\text{out\\_features})`.\n",
    "                If :attr:`bias` is ``True``, the values are initialized from\n",
    "                :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
    "                :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
    "\n",
    "    Examples::\n",
    "\n",
    "        >>> m = nn.Linear(20, 30)\n",
    "        >>> input = torch.randn(128, 20)\n",
    "        >>> output = m(input)\n",
    "        >>> print(output.size())\n",
    "        torch.Size([128, 30])\n",
    "    \"\"\"\n",
    "    __constants__ = ['in_features', 'out_features']\n",
    "    in_features: int\n",
    "    out_features: int\n",
    "    weight: Tensor\n",
    "\n",
    "    def __init__(self, in_features: int, out_features: int,mu, bias: bool = True,\n",
    "                 device=None, dtype=None,J0=0,J1=1) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super().__init__()\n",
    "        self.mu=mu\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.J0=J0\n",
    "        self.J1=J1\n",
    "        self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.empty(out_features, **factory_kwargs))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        #if reset=True:\n",
    "            \n",
    "        # Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\n",
    "        # uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\n",
    "        # https://github.com/pytorch/pytorch/issues/57109\n",
    "        fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n",
    "        bound =weight_tuning/ math.sqrt(fan_in) if fan_in > 0 else 0\n",
    "        #init.uniform_(self.weight, -bound,bound)\n",
    "        #m=standard_t(self.mu,(self.in_features,self.out_features))\n",
    "        value=self.out_features*self.in_features\n",
    "        #print(int(value/2))\n",
    "        m=np.append(levy_stable.rvs(alpha=self.mu,loc=self.J0,scale=self.J1,beta=0, size=value)[:int(value/2)],(-1*levy_stable.rvs(alpha=self.mu,beta=0, size=value)[:int(value/2)]))\n",
    "        \n",
    "        #m = levy_stable.rvs(alpha=0.5,beta=0,size=self.out_features*self.in_features)\n",
    "        \n",
    "        \n",
    "        a=torch.Tensor(m).resize(self.out_features,self.in_features)\n",
    "        #a=m.sample(torch.Size([self.in_features*self.out_features]))[:,0]\n",
    "        #a=a.resize(self.out_features,self.in_features)\n",
    "        self.weight=torch.nn.Parameter(a)\n",
    "        #init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = init._calculate_fan_in_and_fan_out(self.bias)\n",
    "            bound =weight_tuning/ math.sqrt(fan_in) if fan_in > 0 else 0\n",
    "            init.uniform_(self.bias, -bound, bound)\n",
    "            #init.uniform_(self.weight, -bound,bound)\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        return F.linear(input, self.weight, self.bias)\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return 'in_features={}, out_features={}, bias={}'.format(\n",
    "            self.in_features, self.out_features, self.bias is not None\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "deafe7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "#torch.cuda.is_available()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from torch.autograd.functional import jacobian\n",
    "#import torch.autograd.functional\n",
    "import time\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "torch.set_default_dtype(torch.float64)\n",
    "batch_size=100\n",
    "input_size=784\n",
    "output_size=784\n",
    "hidden_state_size=10\n",
    "N=28\n",
    "no_of_layer=2\n",
    "\n",
    "\n",
    "\n",
    "font = {\n",
    "        'size'   : 26}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "class AE(nn.Module):\n",
    "    def __init__(self, input_shape,hidden_layer_shape,encoder_output_shape,n,mu,xinit=torch.eye(batch_size,input_size),xfinal=torch.eye(batch_size,input_size),hidden=torch.eye(10,input_size),J0=0,J1=1):\n",
    "        super().__init__()\n",
    "        self.mu=mu\n",
    "        self.encoder_output_layer = Linear(\n",
    "            in_features=input_shape, out_features=encoder_output_shape\n",
    "        ,mu=self.mu,bias=False,J0=J0,J1=J1)\n",
    "        self.decoder_output_layer = Linear(\n",
    "            in_features=encoder_output_shape, out_features=input_shape\n",
    "        ,mu=self.mu,bias=False,J0=J0,J1=J1)\n",
    "\n",
    "        #self.encoder_input_layer.weight=torch.nn.Parameter(torch.rand(self.encoder_input_layer.weight.size))\n",
    "        \n",
    "        self.number_of_layers=n\n",
    "        self.xinit=xinit\n",
    "        self.xfinal=xfinal\n",
    "        self.hidden=hidden\n",
    "\n",
    "    def forward(self, features):\n",
    "        reconstructed=self.internals(features)\n",
    "        return reconstructed\n",
    "    \n",
    "    def internals(self,features):\n",
    "        code=self.encoder(features)\n",
    "        self.hidden=code\n",
    "        #print(\"hidden state:\"+str(code))\n",
    "        reconstructed=self.decoder(code)\n",
    "        return reconstructed\n",
    "    \n",
    "    def encoder(self,features):\n",
    "\n",
    "\n",
    "        code = self.encoder_output_layer(features)\n",
    "        result = torch.tanh(code)\n",
    "        return code\n",
    "    \n",
    "    def decoder(self,code):  \n",
    "        activation = self.decoder_output_layer(code)\n",
    "        reconstructed = torch.tanh(activation)\n",
    "        return reconstructed\n",
    "    \n",
    "    def xfinals(self):\n",
    "        return self.xfinal\n",
    "    \n",
    "    def xinits(self):\n",
    "        return self.xinit\n",
    "    \n",
    "    def hiddens(self):\n",
    "        return self.hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fb48e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#transform=\n",
    "train_set = torchvision.datasets.FashionMNIST(\"./data\", download=True, transform=\n",
    "                                                transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "]))\n",
    "test_set = torchvision.datasets.FashionMNIST(\"./data\", download=True, train=False, transform=\n",
    "                                               transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "]))  \n",
    "train_loader = torch.utils.data.DataLoader(train_set, \n",
    "                                           batch_size=batch_size,shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_set,\n",
    "                                          batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a05e7a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# create a model from `AE` autoencoder class\n",
    "# load it to the specified device, either gpu or cpu\n",
    "mu=1\n",
    "#model = AE(input_size,output_size,hidden_state_size,no_of_layer,mu).to(device)\n",
    "\n",
    "# create an optimizer object\n",
    "# Adam optimizer with learning rate 1e-3\n",
    "\n",
    "#optimizer =torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# mean-squared error loss\n",
    "#criterion = nn.MSELoss()\n",
    "\n",
    "#print(model.encoder_input_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8aadc777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "epochs=1000\n",
    "asymptotic_repetition=150\n",
    "\n",
    "\n",
    "#projected_jacobian=[]\n",
    "ave_len=5\n",
    "\n",
    "\n",
    "no_of_images,no_of_repetition=20,50\n",
    "spectral_calculation=5\n",
    "colour=np.arange(1,no_of_repetition+1)\n",
    "perturbation_strength=10**(-6)\n",
    "noise_strength=10**(-3)\n",
    "interval=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a37cb727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(inputs,strength):\n",
    "    #print(inputs.size())\n",
    "    noise = torch.randn_like(inputs)*strength*torch.max(inputs)\n",
    "    result=inputs + noise\n",
    "    return result\n",
    "def add_powerlaw_noise(input_size,batch_size,strength,images):\n",
    "    ##input size here is the side of the image 28 \n",
    "    m = Pareto(torch.tensor([1.0]), torch.tensor([1.0]))\n",
    "    res=m.sample(images.size())\n",
    "\n",
    "    temp=res/np.sqrt(res.var())/N/batch_size*strength\n",
    "    noise=temp-temp.mean()\n",
    "    #if print_bool:\n",
    "     #   plt.title(powerlaw_noise print)\n",
    "      #  plt.hist(noise.flatten(),density=True, bins='auto', histtype='stepfilled')\n",
    "        \n",
    "      #  plt.show()\n",
    "    #print(noise[:,:,:,:,0].size())\n",
    "    return noise[:,:,0]+images\n",
    "\n",
    "def validation(test_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "     #valid_loss = criterion(outputs, batch_features.view(batch_size,-1).to(device))\n",
    "        loss=0\n",
    "        for batch_features, _ in test_loader:\n",
    "            #input=add_noise(batch_features,).view(100, -1).to(device)\n",
    "            input_image=add_gaussian_noise(batch_features,noise_strength).view(batch_size, -1).to(device)\n",
    "            #batch_feature = batch_features.view(batch_size, -1)\n",
    "            #input_image =add_powerlaw_noise(input_size,batch_size,noise_strength,batch_feature).view(batch_size, -1).to(device)\n",
    "            batch_feature = batch_features.view(batch_size, -1).to(device)\n",
    "            outputs = model(input_image)\n",
    "            valid_loss = criterion(outputs, input_image.to(device)) \n",
    "            #accuracy+=kl_div(outputs,batch_features)/batch_size\n",
    "            loss += valid_loss.item()\n",
    "    return loss/len(test_loader)\n",
    "            \n",
    "def kl_div(output_image,input_image):\n",
    "    accuracy=0\n",
    "    kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "    for i in range(len(input_image)):\n",
    "        input_spectrum=torch.histogram(input_image[i].cpu(), bins=256, density=True)\n",
    "        output_spectrum=torch.histogram(output_image[i].cpu(), bins=256, density=True)\n",
    "        accuracy+=kl_loss(input_spectrum[i],output_spectrum[i])\n",
    "    return accuracy/len(input_image)\n",
    "\n",
    "def iteration(model,initial_inputs,no_of_repetition,epoch):\n",
    "    y_pred=initial_inputs.to(device)\n",
    "    for i in range(no_of_repetition):\n",
    "        x_train=y_pred\n",
    "        #if i==0:\n",
    "           # name=\"progress asymptotic iteration:\"+str(i)+\" \"\n",
    "           # visualisation(x_train[0].cpu().detach(),epoch,name,False)\n",
    "        #if i%5==1:\n",
    "            #name=\"progress asymptotic iteration:\"+str(i)+\" \"\n",
    "            #visualisation(x_train[0].cpu().detach(),epoch,name,False)\n",
    "        y_pred=model(x_train)\n",
    "    return x_train,y_pred,model \n",
    "def asymptotic_jacobian(model,initial_input,no_of_images,no_of_repetition):\n",
    "    ave_jac=1\n",
    "    overall_distribution=np.asarray([])\n",
    "    y_pred=initial_input.to(device)\n",
    "    jacobian=[]\n",
    "    sorteds=np.asarray([])\n",
    "    for j in range(no_of_repetition):\n",
    "        #print(\"here\")\n",
    "        x_train=y_pred\n",
    "        \n",
    "        y_pred=model(x_train)\n",
    "        mean_jacobian=torch.eye(input_size,output_size).to(device)\n",
    "        \n",
    "        for i in range(no_of_images):\n",
    "            x=x_train[i]\n",
    "            res=torch.autograd.functional.jacobian(model,x)\n",
    "            distribution=np.asarray([])\n",
    "            jacobian.append(res)\n",
    "            sorted=np.asarray([])\n",
    "            #if j==no_of_repetition-1\n",
    "            mean_jacobian*=res\n",
    "             #   distribution,sorted=spectral_distribution(res.cpu())\n",
    "              #  overall_distribution=np.concatenate((overall_distribution,distribution),axis=0)\n",
    "              #  spectral=spectral_radius(sorted)\n",
    "              #  sorteds=np.append(sorteds,spectral)\n",
    "\n",
    "        norm=torch.norm(mean_jacobian).cpu()\n",
    "        #mean_jacobian*=(1/np.sqrt(output_size)*norm)**(1/no_of_images)\n",
    "        #mean_jacobian=mean_jacobian/no_of_images\n",
    "        ave_jac*=(1/np.sqrt(output_size)*norm)**(1/no_of_repetition*1/no_of_images)\n",
    "        print(ave_jac)\n",
    "        print(norm)\n",
    "        print(norm**(1/no_of_repetition*1/no_of_images))\n",
    "    #average_jacobian=ave_jac/no_of_repetition\n",
    "    print(jacobian)\n",
    "    return ave_jac,overall_distribution,jacobian,sorteds\n",
    "\n",
    "def spectral_radius(jacobian,no_of_repetition,no_of_images):\n",
    "    #result=[]\n",
    "   \n",
    "    #output=initial_input.to(device)\n",
    "   # product=torch.eye(n=input_size,m=output_size).to(device)\n",
    "    \n",
    "    spectral=0\n",
    "\n",
    "    \n",
    "        \n",
    "    #res=torch.autograd.functional.jacobian(model.internals,initial_input)\n",
    "    #product=torch.matmul(product,res)\n",
    "    #output=model(initial_input)\n",
    "   # initial_input=output\n",
    "    \n",
    "    s,v=torch.linalg.eig(jacobian)\n",
    " #   #print(s)\n",
    "    abs=torch.abs(s)\n",
    "    \n",
    "    spectral=torch.max(abs).item()\n",
    "    return spectral\n",
    "\n",
    "def poincare_plot(model,initial_input,dimension_vector,no_of_repetition,colour,epoch):\n",
    "    xt=[]\n",
    "    xtminus=[]\n",
    "    \n",
    "    output=initial_input\n",
    "    \n",
    "    for i in range(no_of_repetition):\n",
    "        \n",
    "        initial_input=output\n",
    "        output=model(initial_input)\n",
    "        \n",
    "        xt.append(1/output_size*torch.dot(output,dimension_vector).item())\n",
    "        xtminus.append(1/output_size*torch.dot(initial_input,dimension_vector).item())\n",
    "    \n",
    "    return xt,xtminus\n",
    "  \n",
    "    \n",
    "\n",
    "\n",
    "def asymptotic_distance(xinfinity_unperturbed,xinfinity_perturbed,perturbation):\n",
    "    result=[]\n",
    "    for i in range(len(xinfinity_unperturbed)):\n",
    "    \n",
    "        sum=0\n",
    "        \n",
    "        for j in range(len(xinfinity_unperturbed[i])):\n",
    "            \n",
    "            temp=np.linalg.norm(xinfinity_unperturbed[i][j]-xinfinity_perturbed[i][j])\n",
    "            sum+=temp\n",
    "        \n",
    "        result.append(1/output_size*1/len(xinfinity_unperturbed[i])*sum) \n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def calculation(model,no_of_images,no_of_repetition,ave_jacobian,spectral_radiuses,image,epoch,mu,J0,J1):\n",
    "    spectral=0\n",
    "    \n",
    "    model_clone=AE(input_size,input_size,hidden_state_size,no_of_layer,mu,J0=J0,J1=J1).to(device)\n",
    "    model_clone.load_state_dict(copy.deepcopy(model.state_dict()))\n",
    "    distributions=np.asarray([])\n",
    "    x_train,y_pred,model_clone=iteration(model_clone,image,asymptotic_repetition,epoch)   \n",
    "    #ave_jac,distributions,jacobian,sorteds= asymptotic_jacobian(model_clone,x_train,no_of_images,no_of_repetition)\n",
    "    ave_jac=[]\n",
    "    #np.savetxt(\"jacobian epoch\"+str(epoch)+\".txt\",sorteds)\n",
    "    #print(\"distribution size\")\n",
    "    #print(distributions.size)\n",
    "    #print(\"sorted size\")\n",
    "    #print(sorteds.size)\n",
    "    #average_jacobian.append(ave_jac)\n",
    "    #x = [ele.real for ele in distributions]\n",
    "    ## extract imaginary part\n",
    "    #y = [ele.imag for ele in distributions]\n",
    "    #plt.title(\"real and imaginary part of eigenvalue\")\n",
    "    #plt.scatter(x, y)\n",
    "    #plt.ylabel('Imaginary')\n",
    "    #plt.xlabel('Real')\n",
    "    #plt.xscale(\"log\")\n",
    "    #plt.yscale(\"log\")\n",
    "    #plt.xlim(-1,1)\n",
    "    #plt.ylim(-1,1)\n",
    "    #plt.savefig(\"epoch:\"+str(epoch+1)+\"number of iteration:\"+str(no_of_repetition)+\"eigenvalue scatter plot.jpg\",bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    #plt.title(\"modulus of eigenvalue in log log plot \")\n",
    "    #plt.hist(sorteds, density=True, bins='auto', histtype='stepfilled')\n",
    "    #plt.yscale(\"log\")\n",
    "    #plt.xscale(\"log\")\n",
    "\n",
    "    #plt.savefig(\"epoch:\"+str(epoch+1)+\"number of iteration:\"+str(no_of_repetition)+\"eigenvalue distribution.jpg\",bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "\n",
    "   # for i in range(no_of_images):\n",
    "    \n",
    "        #spectral+=spectral_radius(sorteds,no_of_repetition,no_of_images)\n",
    "    #spectral=sorteds.mean()\n",
    "    \n",
    "    #spectral_radiuses.append(spectral)\n",
    "    #print(spectral/no_of_images)\n",
    "    \n",
    "    return x_train,y_pred,average_jacobian,spectral_radiuses,model_clone\n",
    "\n",
    "\n",
    "def asymptotic_iteration(model_new,initial_inputs,perturbed_inputs,no_of_repetition,no_of_image,cutoff):\n",
    "    \n",
    "    y_pred_unperturbed=initial_inputs.to(device)\n",
    "    y_pred_perturbed=perturbed_inputs.to(device)\n",
    "\n",
    "    distance=[]\n",
    "    hidden_layer=[]\n",
    "    hiddens=[]\n",
    "    chaos=0\n",
    "    ave_jac=[]\n",
    "    #ave_jac,distributions,jacobian,sorteds= asymptotic_jacobian(model_new,y_pred_unperturbed,no_of_images,no_of_repetition)\n",
    "    for i in range(no_of_repetition):\n",
    "        x_train_unperturbed=y_pred_unperturbed\n",
    "        y_pred_unperturbed=model_new(x_train_unperturbed)\n",
    "        \n",
    "       \n",
    "        x_train_perturbed=y_pred_perturbed\n",
    "        y_pred_perturbed=model_new(x_train_perturbed)\n",
    "        \n",
    "\n",
    "        \n",
    "        hidden = model.hiddens()\n",
    "\n",
    "        hidden_layer.append(torch.sum(hidden,dim=1)[0].cpu().detach().numpy()/10)\n",
    "        hiddens.append(torch.sum(hidden,dim=1).cpu().detach().numpy()/10)\n",
    "        \n",
    "        #visualisation(y_pred.view(batch_size,-1)[0].cpu().detach(),epoch)\n",
    "\n",
    "\n",
    "        #diff=0\n",
    "        diff=torch.ones(1,device=device)\n",
    "        temp=0\n",
    "        #print(len(cutoff))\n",
    "        for j in range(no_of_image):\n",
    "            result=torch.norm(y_pred_unperturbed[j]-y_pred_perturbed[j])\n",
    "\n",
    "            if np.isinf(result.cpu().detach().numpy()) or np.isnan(result.cpu().detach().numpy())  :\n",
    "                result=torch.Tensor([1*10**38]).to(device)\n",
    "                print(\"infinity\")\n",
    "            if result.cpu().detach().numpy()<2**-52:\n",
    "                result=torch.Tensor([2**-52]).to(device)\n",
    "            diff*=result**(1/no_of_image)\n",
    "            \n",
    "            #print(j)\n",
    "            if result>cutoff[j] and i==no_of_repetition-1:\n",
    "                chaos+=1\n",
    "        if np.isinf(diff.cpu().detach().numpy()) or np.isnan(diff.cpu().detach().numpy()):\n",
    "            diff=torch.Tensor([1*10**38]).to(device)\n",
    "            print(\"infinity\")\n",
    "\n",
    "            \n",
    "        if diff.cpu().detach().numpy()<2**-52:\n",
    "            diff=torch.Tensor([2**-52]).to(device)\n",
    "        distance.append(diff.cpu().detach().numpy())\n",
    "\n",
    "    return distance,hidden_layer,chaos/no_of_image,ave_jac\n",
    "\n",
    "def visualisation(xfinals,epoch,name,bool):\n",
    "    plt.imshow(xfinals.reshape(N,N), cmap=\"gray\")\n",
    "    if bool:\n",
    "        plt.savefig(str(name)+\" epoch:\"+str(epoch+1)+\".jpg\")\n",
    "    plt.show()\n",
    "    print(str(name)+\" epoch:\"+str(epoch+1)+\".jpg\")\n",
    "    \n",
    "def divergence(values):\n",
    "    result=np.abs(values[-1]-values[-2])\n",
    "    if result>np.abs(values[2]-values[1]):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def spectral_radius(sorted):\n",
    "    if len(sorted)==0:\n",
    "        return 0\n",
    "    return sorted[0]\n",
    "\n",
    "def spectral_distribution(input_matrix):\n",
    "    result=[]\n",
    "    count=0\n",
    "    s,v=torch.linalg.eig(input_matrix)\n",
    "    #return s\n",
    "    for i in range(len(s)):\n",
    "        if np.abs(s[i].cpu())<2**-52:\n",
    "            count+=1\n",
    "        \n",
    "    sorted, indices=torch.sort(torch.abs(s),dim=-1,descending=True)\n",
    "    #for index in indices.cpu():\n",
    "     #   if index<=len(s)-count:\n",
    "     #       result.append(s[index])\n",
    "    #print(sorted)\n",
    "    return s,sorted[:-count]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108432b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:776: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spectral_radiuses=[]\n",
    "average_jacobian=[]\n",
    "xinfinity=[]\n",
    "xpinfinity=[]\n",
    "training_loss=[]\n",
    "validation_loss=[]\n",
    "asymptotic_dist=[]\n",
    "#diverge=[]\n",
    "start=time.time()\n",
    "print(\"running\")\n",
    "#strength=0.1\n",
    "#epochs=10\n",
    "mu=1\n",
    "dmu=1/epochs\n",
    "\n",
    "init_compute=True\n",
    "chao=[]\n",
    "noise_print=False\n",
    "repeats=100\n",
    "average_chaos=[]\n",
    "first_moment=[]\n",
    "second_moment=[]\n",
    "third_moment=[]\n",
    "fourth_moment=[]\n",
    "for i in range(repeats):\n",
    "    mu=1\n",
    "    chao=[]\n",
    "    asy_dist=[]\n",
    "    print(i)\n",
    "    for epoch in range(epochs+1):\n",
    "        loss = 0\n",
    "        #mu+=dmu\n",
    "        #print(mu)\n",
    "        if epoch==0:\n",
    "            for batch_features, _ in train_loader:\n",
    "            # reshape mini-batch data to [1000, 784] matrix\n",
    "            # load it to the active device\n",
    "                input_image =add_gaussian_noise(batch_features,noise_strength).view(batch_size, -1).to(device)\n",
    "        \n",
    "        model = AE(input_size,output_size,hidden_state_size,no_of_layer,mu,J0=J0,J1=J1).to(device)           \n",
    "        save_image=input_image\n",
    "        perturbed_inputs=add_gaussian_noise(input_image,perturbation_strength)\n",
    "        inits=0\n",
    "    \n",
    "        for value in model.parameters():\n",
    "\n",
    "            first,second,third,fourth=stats(value)\n",
    "            first_moment.append(first.cpu().detach().numpy())\n",
    "            second_moment.append(second.cpu().detach().numpy())\n",
    "            third_moment.append(third.cpu().detach().numpy())\n",
    "            fourth_moment.append(fourth.cpu().detach().numpy())\n",
    "            inits+=1\n",
    "        cutoff=[]\n",
    "        for j in range(no_of_images):\n",
    "            cutoff.append(torch.norm(perturbed_inputs[j]-input_image[j]))\n",
    "        model_clone=AE(input_size,input_size,hidden_state_size,no_of_layer,mu,J0=J0,J1=J1).to(device)\n",
    "        model_clone.load_state_dict(copy.deepcopy(model.state_dict()))\n",
    "\n",
    "        #spectral_radiuses=[]\n",
    "        x_train_perturbed,y_pred_perturbed,average_jacobian,spectral_radiuses,model_clone=calculation(model,no_of_images,no_of_repetition,average_jacobian,spectral_radiuses,perturbed_inputs,epoch,mu,J0,J1)\n",
    "        x_train_unperturbed,y_pred_unperturbed,average_jacobian,spectral_radiuses,model_clone=calculation(model,no_of_images,no_of_repetition,average_jacobian,spectral_radiuses,input_image,epoch,mu,J0,J1)\n",
    "\n",
    "        distance,hidden,chaos,ave_jac=asymptotic_iteration(model_clone,y_pred_unperturbed,y_pred_perturbed,no_of_repetition,no_of_images,cutoff)\n",
    "          \n",
    "        asy_dist.append(distance[-1])\n",
    "        chao.append(chaos)\n",
    "        #print(ave_jac)\n",
    "        mu+=dmu\n",
    "    print(\"here\\n\") \n",
    "    np.savetxt(\"average_chaos\"+str(i)+\".txt\",chao)\n",
    "    average_chaos.append(chao)\n",
    "    #print(average_chaos)\n",
    "    asymptotic_dist.append(asy_dist)\n",
    "    np.savetxt(\"asymptotic distance\"+str(i)+\".txt\",asy_dist)\n",
    "\n",
    "\n",
    "end=time.time()\n",
    "print(end-start)\n",
    "\n",
    "#print(chao)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ad4b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(moment):\n",
    "    moment=np.asarray(moment)\n",
    "    moment=moment.reshape(repeats,epochs+1,2)\n",
    "    #moment=np.mean(moment,axis=0)\n",
    "    moment=np.abs(moment)\n",
    "    moment=geometric_mean(moment)\n",
    "    return moment\n",
    "def moment_treatment(mu,moment,indicator):\n",
    "    \n",
    "    moment=np.asarray(moment)\n",
    "    moment=moment.reshape(repeats,epochs+1,2)\n",
    "    #moment=np.mean(moment,axis=0)\n",
    "    moment=np.abs(moment)\n",
    "    moment=geometric_mean(moment)\n",
    "    #if indicator==\"first\"\n",
    "        \n",
    "    plt.plot(mu,moment.T[0])\n",
    "    plt.ylabel(indicator+\" moment\")\n",
    "    plt.xlabel(\"exponent\")\n",
    "   \n",
    "    plt.title(indicator+\" moment vs exponent graph for t distribution first layer\")\n",
    "    np.savetxt(indicator+\" moment vs exponent graph for t distribution layer 1.txt\",moment.T[0])\n",
    "    plt.savefig(indicator+\" moment vs exponent graph for t distribution layer 1.jpg\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.show()\n",
    "    plt.plot(mu,moment.T[1])\n",
    "    plt.ylabel(indicator+\" moment\")\n",
    "    plt.xlabel(\"exponent\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.title(indicator+\" moment vs exponent graph for t distribution second layer\")\n",
    "    np.savetxt(indicator+\" moment vs exponent graph for t distribution layer 2.txt\",moment.T[1])\n",
    "    plt.savefig(indicator+\" moment vs exponent graph for t distribution layer 2.jpg\")\n",
    "    plt.show()\n",
    "    \n",
    "def chaos_treatment(mu,chaos,indicator):\n",
    "    chaos=np.asarray(chaos)\n",
    "    if indicator==\"asymptotic distance\":\n",
    "        chaos=geometric_mean(chaos)\n",
    "        print(chaos.size)\n",
    "    else:\n",
    "        chaos=np.mean(chaos,axis=0)\n",
    "    \n",
    "    \n",
    "    plt.plot(mu,chaos)\n",
    "    plt.ylabel(indicator)\n",
    "    plt.xlabel(\"exponent\")\n",
    "    if indicator==\"asymptotic distance\":\n",
    "        print(\"here\")\n",
    "        plt.yscale(\"log\")\n",
    "    plt.title(indicator+\" vs exponent graph for t distribution \")\n",
    "    np.savetxt(indicator+\" vs exponent graph for t distribution.txt\",chaos)\n",
    "    plt.savefig(indicator+\" vs exponent graph for t distribution.jpg\")\n",
    "    plt.show()\n",
    " \n",
    "def geometric_mean(mean):\n",
    "    result=1\n",
    "    for i in range(len(mean)):\n",
    "        result*=mean[i]**(1/len(mean))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4d3c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_value=np.linspace(1,2,epochs+1)\n",
    "\n",
    "    \n",
    "moment_treatment(mu_value,first_moment,\"first\")\n",
    "moment_treatment(mu_value,second_moment,\"second\")\n",
    "moment_treatment(mu_value,third_moment,\"third\")\n",
    "moment_treatment(mu_value,fourth_moment,\"fourth\")\n",
    "first_moment_1=processing(first_moment)\n",
    "second_moment_1=processing(second_moment)\n",
    "result=[]\n",
    "vertical=[]\n",
    "for i in range(len(first_moment_1)):\n",
    "    #print(first_moment_1[i]/second_moment_1[i])\n",
    "    result.append(first_moment_1[i]/second_moment_1[i])\n",
    "    vertical.append(1/second_moment_1[i])\n",
    "plt.plot(result[0],vertical[0])\n",
    "plt.show()\n",
    "plt.plot(result[1],vertical[1])\n",
    "#print(result)\n",
    "plt.show()\n",
    "chaos_treatment(mu_value,average_chaos,\"percentage chaos\")\n",
    "print(np.asarray(asymptotic_dist).size)\n",
    "chaos_treatment(mu_value,asymptotic_dist,\"asymptotic distance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4677e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057cd14e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c805b909",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
