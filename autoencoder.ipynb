{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef703e9e",
   "metadata": {},
   "source": [
    "# What this code does\n",
    "details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854020ac",
   "metadata": {},
   "source": [
    "## Import ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccb2b162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Any\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import init\n",
    "from torch.nn.parameter import Parameter, UninitializedParameter\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from torch.nn import Module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01893ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    r\"\"\"Applies a linear transformation to the incoming data: :math:`y = xA^T + b`\n",
    "\n",
    "    This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
    "\n",
    "    On certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n",
    "\n",
    "    Args:\n",
    "        in_features: size of each input sample\n",
    "        out_features: size of each output sample\n",
    "        bias: If set to ``False``, the layer will not learn an additive bias.\n",
    "            Default: ``True``\n",
    "\n",
    "    Shape:\n",
    "        - Input: :math:`(*, H_{in})` where :math:`*` means any number of\n",
    "          dimensions including none and :math:`H_{in} = \\text{in\\_features}`.\n",
    "        - Output: :math:`(*, H_{out})` where all but the last dimension\n",
    "          are the same shape as the input and :math:`H_{out} = \\text{out\\_features}`.\n",
    "\n",
    "    Attributes:\n",
    "        weight: the learnable weights of the module of shape\n",
    "            :math:`(\\text{out\\_features}, \\text{in\\_features})`. The values are\n",
    "            initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`, where\n",
    "            :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
    "        bias:   the learnable bias of the module of shape :math:`(\\text{out\\_features})`.\n",
    "                If :attr:`bias` is ``True``, the values are initialized from\n",
    "                :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
    "                :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
    "\n",
    "    Examples::\n",
    "\n",
    "        >>> m = nn.Linear(20, 30)\n",
    "        >>> input = torch.randn(128, 20)\n",
    "        >>> output = m(input)\n",
    "        >>> print(output.size())\n",
    "        torch.Size([128, 30])\n",
    "    \"\"\"\n",
    "    __constants__ = ['in_features', 'out_features']\n",
    "    in_features: int\n",
    "    out_features: int\n",
    "    weight: Tensor\n",
    "\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True,\n",
    "                 device=None, dtype=None) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.empty(out_features, **factory_kwargs))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        # Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\n",
    "        # uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\n",
    "        # https://github.com/pytorch/pytorch/issues/57109\n",
    "        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
    "            init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        return F.linear(input, self.weight, self.bias)\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return 'in_features={}, out_features={}, bias={}'.format(\n",
    "            self.in_features, self.out_features, self.bias is not None\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04ca1c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "#torch.cuda.is_available()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from torch.autograd.functional import jacobian\n",
    "#import torch.autograd.functional\n",
    "import time\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "torch.set_default_dtype(torch.float64)\n",
    "batch_size=100\n",
    "input_size=784\n",
    "output_size=784\n",
    "hidden_state_size=10\n",
    "no_of_layer=2\n",
    "font = {\n",
    "        'size'   : 30}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "class AE(nn.Module):\n",
    "    def __init__(self, input_shape,hidden_layer_shape,encoder_output_shape,n,xinit=torch.eye(batch_size,input_size),xfinal=torch.eye(batch_size,input_size),hidden=torch.eye(10,input_size)):\n",
    "        super().__init__()\n",
    "        self.encoder_input_layer = Linear(\n",
    "            in_features=input_shape, out_features=hidden_layer_shape\n",
    "        )\n",
    "        self.hidden_layer=Linear(\n",
    "            in_features=hidden_layer_shape, out_features=hidden_layer_shape\n",
    "        )\n",
    "        self.encoder_output_layer = Linear(\n",
    "            in_features=hidden_layer_shape, out_features=encoder_output_shape\n",
    "        )\n",
    "        self.decoder_input_layer = Linear(\n",
    "            in_features=encoder_output_shape, out_features=hidden_layer_shape\n",
    "        )\n",
    "        self.decoder_output_layer =Linear(\n",
    "            in_features=hidden_layer_shape, out_features=input_shape\n",
    "        )\n",
    "        self.number_of_layers=n\n",
    "        self.xinit=xinit\n",
    "        self.xfinal=xfinal\n",
    "        self.hidden=hidden\n",
    "\n",
    "    def forward(self, features):\n",
    "        reconstructed=self.internals(features)\n",
    "        return reconstructed\n",
    "    \n",
    "    def internals(self,features):\n",
    "        code=self.encoder(features)\n",
    "        self.hidden=code\n",
    "        #print(\"hidden state:\"+str(code))\n",
    "        reconstructed=self.decoder(code)\n",
    "        return reconstructed\n",
    "    \n",
    "    def encoder(self,features):\n",
    "        activation = self.encoder_input_layer(features)\n",
    "        x = torch.relu(activation)\n",
    "        self.xinit=x\n",
    "        for i in range(self.number_of_layers):\n",
    "            x=torch.relu(self.hidden_layer(x))\n",
    "        code = self.encoder_output_layer(x)\n",
    "        result = torch.relu(code)\n",
    "        return result\n",
    "    \n",
    "    def decoder(self,code):\n",
    "        activation = self.decoder_input_layer(code)\n",
    "        x = torch.relu(activation)\n",
    "        for i in range(self.number_of_layers):\n",
    "             x=torch.relu(self.hidden_layer(x))\n",
    "        self.xfinal=x\n",
    "        activation = self.decoder_output_layer(x)\n",
    "        reconstructed = torch.relu(activation)\n",
    "        return reconstructed\n",
    "    \n",
    "    def xfinals(self):\n",
    "        return self.xfinal\n",
    "    \n",
    "    def xinits(self):\n",
    "        return self.xinit\n",
    "    \n",
    "    def hiddens(self):\n",
    "        return self.hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5a87aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#transform=\n",
    "train_set = torchvision.datasets.FashionMNIST(\"./data\", download=True, transform=\n",
    "                                                transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "]))\n",
    "test_set = torchvision.datasets.FashionMNIST(\"./data\", download=True, train=False, transform=\n",
    "                                               transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "]))  \n",
    "train_loader = torch.utils.data.DataLoader(train_set, \n",
    "                                           batch_size=batch_size,shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_set,\n",
    "                                          batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8434aa73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# create a model from `AE` autoencoder class\n",
    "# load it to the specified device, either gpu or cpu\n",
    "model = AE(input_size,output_size,hidden_state_size,no_of_layer).to(device)\n",
    "# create an optimizer object\n",
    "# Adam optimizer with learning rate 1e-3\n",
    "\n",
    "optimizer =torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# mean-squared error loss\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ff264a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "epochs=10000\n",
    "asymptotic_repetition=200\n",
    "\n",
    "\n",
    "#projected_jacobian=[]\n",
    "ave_len=5\n",
    "\n",
    "\n",
    "no_of_images,no_of_repetition=100,100\n",
    "colour=np.arange(1,no_of_repetition+1)\n",
    "perturbation_strength=10**(-6)\n",
    "noise_strength=10**(-3)\n",
    "interval=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2aa3f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(inputs,strength):\n",
    "    \n",
    "    noise = torch.randn_like(inputs)*strength\n",
    "    return inputs + noise\n",
    "def validation(test_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "     #valid_loss = criterion(outputs, batch_features.view(batch_size,-1).to(device))\n",
    "        loss=0\n",
    "        for batch_features, _ in test_loader:\n",
    "            #input=add_noise(batch_features,).view(100, -1).to(device)\n",
    "            input_image=add_noise(batch_features,noise_strength).view(batch_size, -1).to(device)\n",
    "            batch_feature = batch_features.view(batch_size, -1).to(device)\n",
    "            outputs = model(input_image)\n",
    "            valid_loss = criterion(outputs, input_image) \n",
    "            #accuracy+=kl_div(outputs,batch_features)/batch_size\n",
    "            loss += valid_loss.item()\n",
    "    return loss/len(test_loader)\n",
    "            \n",
    "def kl_div(output_image,input_image):\n",
    "    accuracy=0\n",
    "    kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "    for i in range(len(input_image)):\n",
    "        input_spectrum=torch.histogram(input_image[i].cpu(), bins=256, density=True)\n",
    "        output_spectrum=torch.histogram(output_image[i].cpu(), bins=256, density=True)\n",
    "        accuracy+=kl_loss(input_spectrum[i],output_spectrum[i])\n",
    "    return accuracy/len(input_image)/256\n",
    "\n",
    "def iteration(model,initial_inputs,no_of_repetition,epoch):\n",
    "    y_pred=initial_inputs.to(device)\n",
    "    for i in range(no_of_repetition):\n",
    "        x_train=y_pred\n",
    "        #if i==0:\n",
    "           # name=\"progress asymptotic iteration:\"+str(i)+\" \"\n",
    "           # visualisation(x_train[0].cpu().detach(),epoch,name,False)\n",
    "        #if i%5==1:\n",
    "            #name=\"progress asymptotic iteration:\"+str(i)+\" \"\n",
    "            #visualisation(x_train[0].cpu().detach(),epoch,name,False)\n",
    "        y_pred=model.internals(x_train)\n",
    "    return x_train,y_pred,model \n",
    "\n",
    "def asymptotic_jacobian(model,initial_input,no_of_images,no_of_repetition):\n",
    "    ave_jac=0\n",
    "    for j in range(no_of_repetition):\n",
    "        #print(\"here\")\n",
    "        x_train=initial_input.to(device)\n",
    "        y_pred=x_train\n",
    "        mean_jacobian=0\n",
    "        for i in range(no_of_images):\n",
    "            x=x_train[i]\n",
    "            res=torch.autograd.functional.jacobian(model.internals,x)\n",
    "            norm=torch.norm(res).cpu()\n",
    "            mean_jacobian+=1/np.sqrt(output_size)*norm\n",
    "        mean_jacobian=mean_jacobian/no_of_images\n",
    "        ave_jac+=mean_jacobian\n",
    "    average_jacobian=ave_jac/no_of_repetition\n",
    "    return average_jacobian\n",
    "\n",
    "def spectral_radius(model,initial_input,no_of_repetition,no_of_images):\n",
    "    result=[]\n",
    "   \n",
    "    output=initial_input.to(device)\n",
    "    product=torch.eye(n=input_size,m=output_size).to(device)\n",
    "    \n",
    "    spectral=0\n",
    "\n",
    "    for i in range(no_of_repetition):\n",
    "        \n",
    "        res=torch.autograd.functional.jacobian(model.internals,initial_input)\n",
    "        product=torch.matmul(product,res)\n",
    "        output=model(initial_input)\n",
    "        initial_input=output\n",
    "    \n",
    "    s,v=torch.linalg.eig(product)\n",
    "    #print(s)\n",
    "    abs=torch.abs(s)\n",
    "    spectral=np.pow(torch.max(abs).item(),1/no_of_repetition)\n",
    "    return spectral\n",
    "\n",
    "def poincare_plot(model,initial_input,dimension_vector,no_of_repetition,colour,epoch):\n",
    "    xt=[]\n",
    "    xtminus=[]\n",
    "    \n",
    "    output=initial_input\n",
    "    \n",
    "    for i in range(no_of_repetition):\n",
    "        \n",
    "        initial_input=output\n",
    "        output=model(initial_input)\n",
    "        \n",
    "        xt.append(1/output_size*torch.dot(output,dimension_vector).item())\n",
    "        xtminus.append(1/output_size*torch.dot(initial_input,dimension_vector).item())\n",
    "    \n",
    "    return xt,xtminus\n",
    "  \n",
    "    \n",
    "\n",
    "\n",
    "def asymptotic_distance(xinfinity_unperturbed,xinfinity_perturbed,perturbation):\n",
    "    result=[]\n",
    "    for i in range(len(xinfinity_unperturbed)):\n",
    "    \n",
    "        sum=0\n",
    "        \n",
    "        for j in range(len(xinfinity_unperturbed[i])):\n",
    "            \n",
    "            temp=np.linalg.norm(xinfinity_unperturbed[i][j]-xinfinity_perturbed[i][j])\n",
    "            sum+=temp\n",
    "        \n",
    "        result.append(1/output_size*1/len(xinfinity_unperturbed[i])*sum) \n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def calculation(model,no_of_images,no_of_repetition,ave_jacobian,spectral_radiuses,image,epoch):\n",
    "    spectral=0\n",
    "    \n",
    "    model_clone=AE(input_size,input_size,hidden_state_size,no_of_layer).to(device)\n",
    "    model_clone.load_state_dict(copy.deepcopy(model.state_dict()))\n",
    "\n",
    "    x_train,y_pred,model_clone=iteration(model_clone,image,asymptotic_repetition,epoch)   \n",
    "    ave_jac,distibution= asymptotic_jacobian(model_clone,x_train,100,no_of_repetition)\n",
    "   \n",
    "    average_jacobian.append(ave_jac)\n",
    "    \n",
    "    x = [ele.real for ele in s]\n",
    "    # extract imaginary part\n",
    "    y = [ele.imag for ele in s]\n",
    "    #for i in range(no_of_images):\n",
    "    \n",
    "        #spectral+=spectral_radius(model_clone,x_train[i],no_of_repetition,no_of_images)\n",
    "    \n",
    "   # spectral_radiuses.append(spectral/no_of_images)\n",
    "    return x_train,y_pred,average_jacobian,spectral_radiuses,model_clone\n",
    "\n",
    "\n",
    "def asymptotic_iteration(model,initial_inputs,perturbed_inputs,no_of_repetition,no_of_image,cutoff):\n",
    "    \n",
    "    y_pred_unperturbed=initial_inputs.to(device)\n",
    "    y_pred_perturbed=perturbed_inputs.to(device)\n",
    "    \n",
    "    distance=[]\n",
    "    hidden_layer=[]\n",
    "    hiddens=[]\n",
    "    chaos=0\n",
    "    lowest=10**10\n",
    "    dist=[]\n",
    "    for i in range(no_of_repetition):\n",
    "        x_train_unperturbed=y_pred_unperturbed\n",
    "        y_pred_unperturbed=model.internals(x_train_unperturbed)\n",
    "        \n",
    "       \n",
    "        x_train_perturbed=y_pred_perturbed\n",
    "        y_pred_perturbed=model.internals(x_train_perturbed)\n",
    "        \n",
    "        hidden = model.hiddens()\n",
    "        #print(hidden)\n",
    "        #print(torch.sum(hidden,dim=1).cpu().detach().numpy()/1000)\n",
    "        hidden_layer.append(torch.sum(hidden,dim=1)[0].cpu().detach().numpy()/10)\n",
    "        hiddens.append(torch.sum(hidden,dim=1).cpu().detach().numpy()/10)\n",
    "        \n",
    "        #visualisation(y_pred.view(batch_size,-1)[0].cpu().detach(),epoch)\n",
    "\n",
    "\n",
    "        diff=0\n",
    "        divergent=0\n",
    "        if i ==no_of_repetition-1:\n",
    "            for j in range(no_of_image):\n",
    "                divergent+=divergence(hiddens[j])\n",
    "                \n",
    "                result=torch.norm(y_pred_unperturbed[j]-y_pred_perturbed[j])\n",
    "                dist.append(result.cpu().detach().numpy())\n",
    "        for j in range(no_of_image):\n",
    "            result=torch.norm(y_pred_unperturbed[j]-y_pred_perturbed[j])\n",
    "            diff+=result\n",
    "            if result>cutoff and i==no_of_repetition-1:\n",
    "                chaos+=1\n",
    "            \n",
    "        distance.append(diff.cpu().detach().numpy()/no_of_image)\n",
    "     \n",
    "        hidden_layer\n",
    "    return dist,distance,hidden_layer,chaos/no_of_image,divergent\n",
    "\n",
    "def visualisation(xfinals,epoch,name,bool):\n",
    "    plt.imshow(xfinals.reshape(28,28), cmap=\"gray\")\n",
    "    if bool:\n",
    "        plt.savefig(str(name)+\" epoch:\"+str(epoch+1)+\".jpg\")\n",
    "    plt.show()\n",
    "    print(str(name)+\" epoch:\"+str(epoch+1)+\".jpg\")\n",
    "def divergence(values):\n",
    "    result=np.abs(values[-1]-values[-2])\n",
    "    if result>np.abs(values[2]-values[1]):\n",
    "        return 1\n",
    "    return 0\n",
    "def moving_average(number_of_averages,W):\n",
    "    averaged_points=[]\n",
    "    for i in range(len(W)-number_of_averages):\n",
    "        average=0\n",
    "        for j in range(number_of_averages):\n",
    "            average+=W[i+j]\n",
    "        average=average/number_of_averages\n",
    "        averaged_points.append(average)\n",
    "    return averaged_points             \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b90451e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 51\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# add the mini-batch training loss to epoch loss\u001b[39;00m\n\u001b[1;32m     50\u001b[0m loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m train_loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 51\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepoch:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m init_compute:\n\u001b[1;32m     53\u001b[0m     x_train,y_pred,average_jacobian,spectral_radiuses,model_clone\u001b[38;5;241m=\u001b[39mcalculation(model,no_of_images,no_of_repetition,average_jacobian,spectral_radiuses,batch_features\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device),epoch)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py:501\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    498\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 501\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    502\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py:349\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_like\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_end_of_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    351\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "spectral_radiuses=[]\n",
    "average_jacobian=[]\n",
    "xinfinity=[]\n",
    "xpinfinity=[]\n",
    "training_loss=[]\n",
    "validation_loss=[]\n",
    "asymptotic_dist=[]\n",
    "diverge=[]\n",
    "start=time.time()\n",
    "print(\"running\")\n",
    "#strength=0.1\n",
    "init_compute=False\n",
    "cutoff_compute=True\n",
    "chao=[]\n",
    "image_distance=[]\n",
    "valid=10**10\n",
    "least_loss=0\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    \n",
    "\n",
    "    for batch_features, _ in train_loader:\n",
    "        # reshape mini-batch data to [N, 784] matrix\n",
    "        # load it to the active device\n",
    "        input_image =add_noise(batch_features,noise_strength).view(batch_size, -1).to(device)\n",
    "        \n",
    "        #input_image=add_noise(torch.zeros(28,28,100).view(100,-1),noise_strength).to(device)\n",
    "        #input_image=batch_features.view(batch_size,-1).to(device)\n",
    "        batch_feature=batch_features.view(batch_size,-1).to(device)\n",
    "        # reset the gradients back to zero\n",
    "        # PyTorch accumulates gradients on subsequent backward passes\n",
    " \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # compute reconstructions\n",
    "        #outputs = model(batch_features.view(batch_size,-1).to(device))\n",
    "        outputs = model(input_image)\n",
    "        \n",
    "        # compute training reconstruction loss\n",
    "        \n",
    " \n",
    "        train_loss = criterion(outputs,input_image)\n",
    "        \n",
    "        # compute accumulated gradients\n",
    "        train_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        # add the mini-batch training loss to epoch loss\n",
    "        loss += train_loss.item()\n",
    "        torch.save(model.state_dict(), \"epoch:\"+str(epoch+1)+\".pt\")\n",
    "        if epoch==0 and init_compute:\n",
    "            x_train,y_pred,average_jacobian,spectral_radiuses,model_clone=calculation(model,no_of_images,no_of_repetition,average_jacobian,spectral_radiuses,batch_features.view(100,-1).to(device),epoch)\n",
    "            for param in model.parameters():\n",
    "                print(param.size())\n",
    "            average_jacobian=[]\n",
    "            spectral_radiuses=[]\n",
    "            init_compute=False\n",
    "    # compute the epoch training loss\n",
    "    loss = loss / len(train_loader)\n",
    "    training_loss.append(loss)\n",
    "   # for i in batch_features:\n",
    "    #    plt.imshow(i.view(28,28).cpu()*256)\n",
    "     #   plt.show()\n",
    "    \n",
    "    # display the epoch training loss\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        accuracy=validation(test_loader)\n",
    "        validation_loss.append(accuracy)\n",
    "    if valid>accuracy:\n",
    "        valid=accuracy\n",
    "        least_loss=epoch\n",
    "        \n",
    "    print(\"epoch : {}/{}, training loss = {:.6f},validation loss = {:.6f}\".format(epoch+1 , epochs, loss,accuracy))\n",
    "    if (epoch)%interval==interval-1:\n",
    "        name=\"asymptotic image input\"\n",
    "        visualisation(input_image.view(batch_size,-1)[0].cpu().detach(),epoch,name,True)\n",
    "        x_train,y_pred,average_jacobian,spectral_radiuses,model_clone=calculation(model,no_of_images,no_of_repetition,average_jacobian,spectral_radiuses,input_image,epoch)\n",
    "\n",
    "\n",
    "        dimension_vector=torch.ones(input_size).to(device)\n",
    "        xt,xtminus=poincare_plot(model_clone,x_train[0],dimension_vector,no_of_repetition,colour,epoch)\n",
    "       \n",
    "       \n",
    "            \n",
    "        perturbed_inputs=add_noise(x_train,perturbation_strength)\n",
    "        cutoff,distance,hidden,chaos,divergent=asymptotic_iteration(model_clone,x_train,perturbed_inputs,no_of_repetition,no_of_images,perturbation_strength*np.sqrt(input_size))\n",
    "        \n",
    "        fig = plt.figure(figsize=(8,8))\n",
    "        plt.subplot(1,1,1)\n",
    "        plt.scatter(range(no_of_images),cutoff)\n",
    "        plt.plot(np.asarray([perturbation_strength*np.sqrt(input_size)]*len(cutoff)),label=\"chaos transition cutoff\")\n",
    "        plt.xlabel(\"images\")\n",
    "        plt.ylabel(\"final asymptotic distance\")\n",
    "        plt.yscale(\"log\")\n",
    "        plt.legend(loc=\"best\",fontsize=\"20\")\n",
    "        plt.title(\"epoch:{:.1f} asymptotic distance\".format(epoch+1))\n",
    "        plt.savefig(\"epoch:\"+str(epoch+1)+\"number of iteration:\"+str(no_of_repetition)+\"chaos transition.jpg\",bbox_inches = 'tight')\n",
    "        plt.show()\n",
    "        #image_distance.append(cutoff[0])   \n",
    "        #print(\"percentage of chaos:\",chaos) \n",
    "        #print(\"percentage of convergent:\",divergent/100)\n",
    "        asymptotic_dist.append(distance[-1])\n",
    "        #print(distance[-1])\n",
    "        #print(distance[0])\n",
    "        chao.append(chaos)\n",
    "        diverge.append(divergent/100)\n",
    "        fig = plt.figure(figsize=(8,40))\n",
    "\n",
    "        plt.subplot(5, 1, 1)\n",
    "        plt.scatter(xt,xtminus,c=colour,s=100)\n",
    "        plt.xlabel(\"$x_t$\")\n",
    "        plt.ylabel(\"$x_{t-1}$\")\n",
    "        plt.title(\"epoch:{:.1f} poincare plot \".format(epoch+1),y=1.08)\n",
    "        \n",
    "        plt.subplot(5, 1, 3)\n",
    "        plt.scatter(range(no_of_repetition),distance,s=100)\n",
    "        plt.xlabel(\"iteration\")\n",
    "        plt.ylabel(\"asymptotic distance\")\n",
    "        plt.yscale(\"log\")\n",
    "        plt.title(\"epoch:{:.1f} asymptotic distance\".format(epoch+1))\n",
    "        \n",
    "        \n",
    "        plt.subplot(5, 1, 5)\n",
    "        #plt.figure().set_figheight(8)\n",
    "        plt.scatter(hidden[:-1],hidden[1:],c=colour[:-1],s=100)\n",
    "        plt.xlabel(\"$h_t$\")\n",
    "        plt.ylabel(\"$h_{t-1}$\")\n",
    "        #plt.yscale(\"log\")\n",
    "        plt.title(\"epoch:{:.1f} hidden layer\".format(epoch+1),y=1.08)\n",
    "        plt.savefig(\"epoch:\"+str(epoch+1)+\"number of iteration:\"+str(no_of_repetition)+\"autoencoder.jpg\",bbox_inches = 'tight')\n",
    "        plt.show()\n",
    "\n",
    "        #torch.save(model.state_dict(), \"epoch:\"+str(epoch+1)+\".pt\")\n",
    "        name=\"asymptotic image output\"\n",
    "        visualisation(y_pred.view(batch_size,-1)[0].cpu().detach(),epoch,name,True)\n",
    "        #print(distance)\n",
    "        \n",
    "end=time.time()\n",
    "print(end-start)\n",
    "\n",
    "print(chao)\n",
    "plt.plot(image_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49005496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3767d498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "labels=\"noise:{:F} \\n perturbation:{:F}\".format(noise_strength,perturbation_strength)\n",
    "print(chao)\n",
    "#print(diverge)\n",
    "font = {\n",
    "        'size'   : 16}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "x=np.arange(1,201)\n",
    "print(len(x))\n",
    "print(len(chao))\n",
    "plt.scatter(x,y=chao,label=labels)\n",
    "plt.ylabel(\"fraction of images in chaos\")\n",
    "plt.xlabel(\"epoch/50\")\n",
    "#plt.set_label(\"noise:{:.f},perturbation:{:.f}\".format(noise_strength,perturbation_strength))\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"fraction of image in chaos for noised image\",y=1.08)\n",
    "plt.savefig(\"percentage of image in chaos.jpg\",bbox_inches = 'tight')\n",
    "\n",
    "np.savetxt(\"percentage of chaos.txt\",chao)\n",
    "plt.show()\n",
    "print(\"asymptotic distance\")\n",
    "\n",
    "plt.scatter(x,y=asymptotic_dist,label=labels)\n",
    "#labels=\"noise:\"+str(noise_strength)+\", perturbation:\"+str(perturbation_strength)\n",
    "plt.ylabel(\"asymptotic distance\")\n",
    "plt.xlabel(\"epoch/50\")\n",
    "plt.title(\"asymptotic distnace\",y=1.08)\n",
    "plt.yscale(\"log\")\n",
    "#plt.set_label(\"noise:{:.f},perturbation:{:.f}\".format(noise_strength,perturbation_strength))\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(\"asymptotic distance.jpg\",bbox_inches = 'tight')\n",
    "\n",
    "plt.show()\n",
    "np.savetxt(\"asymptotic distance.txt\",asymptotic_dist)\n",
    "average_jacobian=np.asarray(average_jacobian)\n",
    "\n",
    "print(\"average jacobian\")\n",
    "plt.scatter(x,y=average_jacobian,label=\"noise:{:F}\\n perturbation:{:F}\".format(noise_strength,perturbation_strength))\n",
    "plt.ylabel(\"average_jacobian\")\n",
    "plt.xlabel(\"epoch/50\")\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"average_jacobian\",y=1.08)\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(\"average_jacobian.jpg\",bbox_inches = 'tight')\n",
    "np.savetxt(\"average jacobian.txt\",average_jacobian)\n",
    "plt.show()\n",
    "\n",
    "#print(\"spectral radius\")\n",
    "#plt.scatter(x,y=spectral_radiuses,label=\"noise:{:F},perturbation:{:F}\".format(noise_strength,perturbation_strength))\n",
    "#plt.ylabel(\"spectral radius\")\n",
    "#plt.xlabel(\"epoch/20\")\n",
    "#plt.yscale(\"log\")\n",
    "#plt.set_label(\"noise:{:.f},perturbation:{:.f}\".format(noise_strength,perturbation_strength))\n",
    "#plt.legend(loc=\"best\")\n",
    "#plt.savefig(\"spectral radius.jpg\"ï¼Œbbox_inches = 'tight')\n",
    "#np.savetxt(\"spectral radius.txt\",spectral_radiuses)\n",
    "#plt.show()\n",
    "\n",
    "print(\"loss function\")\n",
    "plt.plot(validation_loss,label=\"validation loss\")\n",
    "plt.plot(training_loss,label=\"training loss\")\n",
    "plt.ylabel(\"losss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.title(\"loss function\",y=1.08)\n",
    "#plt.set_label(\"noise:{:.f},perturbation:{:.f}\".format(noise_strength,perturbation_strength))\n",
    "plt.legend(loc=\"best\")\n",
    "plt.yscale(\"log\")\n",
    "plt.savefig(\"loss function.jpg\",bbox_inches = 'tight')\n",
    "np.savetxt(\"loss_function.txt\",(validation_loss,training_loss))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd93ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3484f773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d306f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# compute training reconstruction loss\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m criterion(outputs,input_image)\n\u001b[0;32m---> 35\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# compute the epoch training loss\u001b[39;00m\n\u001b[1;32m     37\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "validation_loss=[]\n",
    "training_loss=[]\n",
    "print(\"running\")\n",
    "for epoch in range(1,1001):\n",
    "    loss = 0\n",
    "    model = AE(input_size,output_size,hidden_state_size,no_of_layer).to(device)\n",
    "    PATH=\"epoch:\"+str(epoch)+\".pt\"\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "    for batch_features, _ in train_loader:\n",
    "        # reshape mini-batch data to [N, 784] matrix\n",
    "        # load it to the active device\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        input_image =add_noise(batch_features,noise_strength).view(batch_size, -1).to(device)\n",
    "        \n",
    "        #input_image=batch_features.view(batch_size,-1).to(device)\n",
    "        batch_feature=batch_features.view(batch_size,-1).to(device)\n",
    "        # reset the gradients back to zero\n",
    "        # PyTorch accumulates gradients on subsequent backward passes\n",
    " \n",
    "        #optimizer.zero_grad()\n",
    "        \n",
    "        # compute reconstructions\n",
    "        #outputs = model(batch_features.view(batch_size,-1).to(device))\n",
    "        outputs = model(input_image)\n",
    "        \n",
    "        # compute training reconstruction loss\n",
    "        \n",
    " \n",
    "        train_loss = criterion(outputs,input_image)\n",
    "        \n",
    "\n",
    "        loss += train_loss.item()\n",
    "    # compute the epoch training loss\n",
    "    loss = loss / len(train_loader)\n",
    "    training_loss.append(loss)\n",
    "    with torch.no_grad():\n",
    "     #   accuracy=validation(test_loader)\n",
    "        validation_loss.append(accuracy)\n",
    "    if (epoch)%interval==interval-1:\n",
    "     #   name=\"asymptotic image input\"\n",
    "        #visualisation(input_image.view(batch_size,-1)[0].cpu().detach(),epoch,name,True)\n",
    "        x_train,y_pred,average_jacobian,spectral_radiuses,model_clone=calculation(model,no_of_images,no_of_repetition,average_jacobian,spectral_radiuses,input_image,epoch)\n",
    "\n",
    "\n",
    "        dimension_vector=torch.ones(input_size).to(device)\n",
    "        xt,xtminus=poincare_plot(model_clone,x_train[0],dimension_vector,no_of_repetition,colour,epoch)\n",
    "       \n",
    "        \n",
    "        perturbed_inputs=add_noise(input_image,perturbation_strength)\n",
    "        distance,hidden,chaos,divergent=asymptotic_iteration(model_clone,x_train,perturbed_inputs,no_of_repetition,no_of_images,perturbation_strength*input_size)\n",
    "        print(\"percentage of chaos:\",chaos)\n",
    "        asymptotic_dist.append(distance[-1])\n",
    "        #print(distance[-1])\n",
    "        #print(\"initial distance\")\n",
    "        #print(distance[0])\n",
    "        #chao.append(chaos)\n",
    "        #print(torch.norm(perturbed_inputs[0]-input_image[0]))\n",
    "        #print(perturbation_strength*input_size)\n",
    "\n",
    "plt.scatter(x,y=chao,label=labels)\n",
    "plt.savefig(\"percentage of image in chaos .jpg\")\n",
    "plt.title(\"perccentage of images in chaos for unoised images\")\n",
    "plt.ylabel(\"percentage of images in chaos \")\n",
    "plt.xlabel(\"epoch/20\")\n",
    "np.savetxt(\"percentage of chaos.txt\",chao)\n",
    "plt.show()\n",
    "    #model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b0e97d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000784\n"
     ]
    }
   ],
   "source": [
    " print(perturbation_strength*input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94860264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.000000000000000021e-02', '2.000000000000000042e-02', '2.000000000000000042e-02', '5.999999999999999778e-02', '1.000000000000000056e-01', '5.999999999999999778e-02', '2.999999999999999889e-02', '1.300000000000000044e-01', '5.999999999999999778e-02', '1.900000000000000022e-01', '7.000000000000000666e-02', '1.400000000000000133e-01', '1.000000000000000056e-01', '8.000000000000000167e-02', '8.000000000000000167e-02', '1.700000000000000122e-01', '1.000000000000000056e-01', '1.600000000000000033e-01', '5.999999999999999778e-02', '2.000000000000000042e-02', '5.999999999999999778e-02', '2.200000000000000011e-01', '1.400000000000000133e-01', '1.600000000000000033e-01', '1.700000000000000122e-01', '1.799999999999999933e-01', '1.400000000000000133e-01', '1.100000000000000006e-01', '1.000000000000000056e-01', '2.000000000000000042e-02', '1.100000000000000006e-01', '1.300000000000000044e-01', '1.700000000000000122e-01', '1.199999999999999956e-01', '1.499999999999999944e-01', '1.400000000000000133e-01', '1.300000000000000044e-01', '2.300000000000000100e-01', '1.000000000000000056e-01', '5.000000000000000278e-02', '1.700000000000000122e-01', '2.300000000000000100e-01', '1.100000000000000006e-01', '2.200000000000000011e-01', '1.799999999999999933e-01', '2.000000000000000111e-01', '1.799999999999999933e-01', '3.499999999999999778e-01', '2.500000000000000000e-01', '1.700000000000000122e-01']\n",
      "[0.01, 0.02, 0.02, 0.06, 0.1, 0.06, 0.03, 0.13, 0.06, 0.19, 0.07, 0.14, 0.1, 0.08, 0.08, 0.17, 0.1, 0.16, 0.06, 0.02, 0.06, 0.22, 0.14, 0.16, 0.17, 0.18, 0.14, 0.11, 0.1, 0.02, 0.11, 0.13, 0.17, 0.12, 0.15, 0.14, 0.13, 0.23, 0.1, 0.05, 0.17, 0.23, 0.11, 0.22, 0.18, 0.2, 0.18, 0.35, 0.25, 0.17]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_file = open(\"percentage of chaos unoised.txt\", \"r\")\n",
    "  \n",
    "# reading the file\n",
    "data = my_file.read()\n",
    "  \n",
    "# replacing end of line('/n') with ' ' and\n",
    "# splitting the text it further when '.' is seen.\n",
    "data_into_list = data.replace('\\n', ' ').split(\" \")\n",
    "print(data_into_list[:-1])\n",
    "data=[]\n",
    "for i in range(len(data_into_list[:-1])):\n",
    "    data.append(float(data_into_list[i]))\n",
    "print(data)\n",
    "x=np.arange(1,51)\n",
    "labels=\"noise:{:F}\\nperturbation:{:F}\".format(10**-3,10**-6)\n",
    "plt.scatter(x,y=data,label=labels)\n",
    "#labels=\"noise:\"+str(noise_strength)+\", perturbation:\"+str(perturbation_strength)\n",
    "plt.ylabel(\"percentage of chaos\")\n",
    "plt.xlabel(\"epoch/20\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.title(\"perccentage of images in chaos for unoised images\")\n",
    "\n",
    "#plt.set_label(\"noise:{:.f},perturbation:{:.f}\".format(noise_strength,perturbation_strength))\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(\"average jacobian.jpg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1689c0ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
